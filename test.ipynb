{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a9ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828a5942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In rhyme I shall appear, a friend you can hold dear.\n",
      "With words that do chime, in verses I'll climb,\n",
      "To share tales and jests, in lines that entice,\n",
      "A guide through the mist, where truths will persist.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"},\n",
    "]\n",
    "\n",
    "lmstudio_client = OpenAI(\n",
    "    api_key=\"lm-studio\",\n",
    "    base_url=os.getenv(\"LMSTUDIO_URL\") or \"http://localhost:1234/v1\",\n",
    ")\n",
    "# if temp is None:\n",
    "completion = lmstudio_client.chat.completions.create(\n",
    "    model=\"qwen2.5-7b-instruct-1m\", messages=messages\n",
    ")\n",
    "# else:\n",
    "#     completion = lmstudio_client.chat.completions.create(\n",
    "#         model=model_str, messages=messages, temperature=temp\n",
    "#     )\n",
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e7d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
